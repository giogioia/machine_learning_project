{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yDdr0jUpePNp"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install scikit-plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scikitplot.metrics import plot_roc\n",
    "from scikitplot.metrics import plot_precision_recall\n",
    "from scikitplot.metrics import plot_cumulative_gain\n",
    "from scikitplot.metrics import plot_lift_curve\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQXuF9oDXo7B"
   },
   "source": [
    "### MONK1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpUdxuv5pPOz"
   },
   "source": [
    "import and clean train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FlODP3pe0EwX"
   },
   "outputs": [],
   "source": [
    "#import&clean Monk_train 1\n",
    "monk1_train = pd.read_csv('monks-1_train.csv', sep=' ', header= None)\n",
    "monk1_train.drop([0,8], axis=1, inplace = True)\n",
    "rename_dict = {}\n",
    "for i in range(2,8): \n",
    "  rename_dict[i] = f\"attr_{i-1}\"\n",
    "rename_dict.update({1:'target'})\n",
    "monk1_train.rename( columns=rename_dict, inplace =True)\n",
    "monk1_train = monk1_train[list(monk1_train)[1:] + list(monk1_train)[:-6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8BBOwv210ssB"
   },
   "outputs": [],
   "source": [
    "#import&clean Monk_test 1\n",
    "monk1_test = pd.read_csv('monks-1_test.csv', sep=' ', header= None)\n",
    "monk1_test.drop([0,8], axis=1, inplace = True)\n",
    "rename_dict = {}\n",
    "for i in range(2,8): \n",
    "  rename_dict[i] = f\"attr_{i-1}\"\n",
    "rename_dict.update({1:'target'})\n",
    "monk1_test.rename( columns=rename_dict, inplace =True)\n",
    "monk1_test = monk1_test[list(monk1_test)[1:] + list(monk1_test)[:-6]]\n",
    "\n",
    "#remove training set from test set\n",
    "monk_temp = monk1_test.append(monk1_train, ignore_index =True)\n",
    "duplicated_indexes = monk_temp.duplicated(keep=False)\n",
    "monk1_test = monk_temp.drop(monk_temp.loc[duplicated_indexes,:].index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TrKv9Fk7EmPB"
   },
   "outputs": [],
   "source": [
    "X = monk1_train.iloc[:,:-1]\n",
    "y = monk1_train['target']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hNI7lC4_6bDM"
   },
   "outputs": [],
   "source": [
    "#with Pandas get_dummies\n",
    "X_encoded = pd.get_dummies(monk1_train.iloc[:,:-1].astype('str'), prefix_sep='=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "home made gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(func, args):\n",
    "    return func(*args)\n",
    "\n",
    "def create_combination_df():\n",
    "  global params_df, previous_best\n",
    "  params_df = pd.DataFrame(data = list(wrapper(itertools.product, [list(params.values())[_] for _ in range(len(params.keys()))])), columns=list(params.keys()))\n",
    "  params_df = params_df.where(pd.notnull(params_df), None)\n",
    "  params_df['mean_accuracy'] = None\n",
    "  print(\"# of initial combinations: \", len(params_df.loc[params_df.mean_accuracy.isna()]))\n",
    "  previous_best = 0\n",
    "\n",
    "def update_combination_df():\n",
    "  global params_df\n",
    "  params_df = pd.concat([params_df, pd.DataFrame(data = list(wrapper(itertools.product, [list(params.values())[_] for _ in range(len(params.keys()))])), columns=list(params.keys()))], axis=0, ignore_index=True)\n",
    "  params_df = params_df.where(pd.notnull(params_df), None)\n",
    "  print(\"# of new combinations: \", len(params_df.loc[params_df.mean_accuracy.isna()]))\n",
    "\n",
    "def previous_accuracy_higher_than_new(new_best_result):\n",
    "  global previous_best\n",
    "  if previous_best >= new_best_result:\n",
    "      print('Stopping search because no improvements','\\nprevious_best = ',previous_best, '\\nnew_best = ',new_best_result)\n",
    "      previous_best = new_best_result \n",
    "      return True\n",
    "  else:\n",
    "      if previous_best != 0: print(f'Continuing search: new_best ({new_best_result}) vs previous_best ({previous_best} = {round(((new_best_result-previous_best)/previous_best)*100,3)}')\n",
    "      previous_best = new_best_result\n",
    "      return False \n",
    "\n",
    "def update_parameters(percentage_update):\n",
    "    global params\n",
    "    up, low = 1+1*(percentage_update/100), 1-1*(percentage_update/100)\n",
    "    key_list = list(advanced_search.keys())\n",
    "    for key in list(params.keys()):\n",
    "        if key in key_list:\n",
    "            best_param_value = params_df.sort_values(by='mean_accuracy', ascending=False).reset_index().loc[0,key]\n",
    "            if advanced_search[key][1] == 'int':\n",
    "                try: advanced_search[key][2] == 'min=2'\n",
    "                except IndexError: min_value = 1\n",
    "                else: min_value = 2\n",
    "                finally: \n",
    "                        params[key] = [int(round(max(best_param_value-max(best_param_value*(percentage_update/100),1), min_value))) , int(round(max(best_param_value+max(best_param_value*(percentage_update/100),1), min_value)))]                        \n",
    "                        #params[key] = [int(max(best_param_value*low, min_value)), int(max(best_param_value*up, min_value))]\n",
    "            elif advanced_search[key][1] == 'float':\n",
    "                params[key] = [best_param_value*low, best_param_value*up]\n",
    "        else:\n",
    "            best_param_value = params_df.sort_values(by='mean_accuracy', ascending=False).reset_index().loc[0,key]\n",
    "            params[key] = [best_param_value]\n",
    "    update_combination_df()\n",
    "\n",
    "def get_average_performance(num_rep, min_samples_split, min_samples_leaf, max_features, n_estimators):\n",
    "  mean_l = []\n",
    "  for _ in range(num_rep):\n",
    "    clf = RandomForestClassifier(criterion='gini', max_depth=None, min_samples_split= min_samples_split, min_samples_leaf= min_samples_leaf, max_features=max_features, \n",
    "                            n_estimators=n_estimators)\n",
    "    mean_scores = cross_val_score(clf, X_encoded, y, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=True), error_score='raise')\n",
    "    #print('Accuracy: %0.4f (+/- %0.2f)' % (mean_scores.mean(), mean_scores.std() * 2))\n",
    "    mean_l.append(mean_scores.mean())\n",
    "  return (np.array(mean_l).mean())\n",
    "\n",
    "def launch_search(crossval_repetitions=3):\n",
    "  global params_df, temp_index\n",
    "  print('# of crossval_repetitions: ', crossval_repetitions)\n",
    "  temp_index = params_df.loc[params_df.mean_accuracy.isna()].index\n",
    "  for i in temp_index:\n",
    "    try:\n",
    "      #params_df.loc[i,'mean_accuracy'] = get_average_performance(10, params_df.loc[i,'min_samples_split'], params_df.loc[i,'min_samples_leaf'], params_df.loc[i,'max_features'])\n",
    "      params_df.loc[i,'mean_accuracy'] = wrapper(get_average_performance, list([crossval_repetitions]+ [params_df.loc[i,_] for _ in list(params.keys())])) \n",
    "      params_df.loc[i,'#crossval_repetitions'] = int(crossval_repetitions)\n",
    "      print(dict(params_df.loc[i,[_ for _ in list(params_df) if _ != '#crossval_repetitions']]))\n",
    "    except ValueError as E:\n",
    "      print(f'skipped combination {i}:', E)\n",
    "      pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of initial combinations:  2\n",
      "loop 0\n",
      "# of crossval_repetitions:  5\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 40, 'mean_accuracy': 0.9434615384615386}\n",
      "{'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 40, 'mean_accuracy': 0.9365384615384615}\n",
      "# of new combinations:  4\n",
      "loop 1\n",
      "# of crossval_repetitions:  7\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 28, 'mean_accuracy': 0.9471611721611721}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 52, 'mean_accuracy': 0.9558608058608058}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None, 'n_estimators': 28, 'mean_accuracy': 0.9113553113553114}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None, 'n_estimators': 52, 'mean_accuracy': 0.9164835164835166}\n",
      "Continuing search: new_best (0.9558608058608058) vs previous_best (0.9434615384615386 = 1.314\n",
      "# of new combinations:  4\n",
      "loop 2\n",
      "# of crossval_repetitions:  9\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 37, 'mean_accuracy': 0.9579772079772079}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 67, 'mean_accuracy': 0.9686609686609686}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 37, 'mean_accuracy': 0.9466524216524215}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 67, 'mean_accuracy': 0.9449430199430198}\n",
      "Continuing search: new_best (0.9686609686609686) vs previous_best (0.9558608058608058 = 1.339\n",
      "# of new combinations:  4\n",
      "loop 3\n",
      "# of crossval_repetitions:  10\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 50, 'mean_accuracy': 0.9545512820512819}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 84, 'mean_accuracy': 0.9542307692307693}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 50, 'mean_accuracy': 0.9400000000000001}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 84, 'mean_accuracy': 0.9476923076923077}\n",
      "Stopping search because no improvements \n",
      "previous_best =  0.9686609686609686 \n",
      "new_best =  0.9545512820512819\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_split': [2,4],\n",
    "              'min_samples_leaf': [2],\n",
    "              'max_features': [None],\n",
    "              'n_estimators': [40]}\n",
    "advanced_search = {'n_estimators':[30, 'int'], 'min_samples_leaf':[20,'int']}\n",
    "\n",
    "create_combination_df()\n",
    "for loop in range(10):\n",
    "  print(f'loop {loop}')\n",
    "  launch_search(crossval_repetitions=min(5+(loop*2),10))\n",
    "  if previous_accuracy_higher_than_new(params_df.loc[temp_index,'mean_accuracy'].max()):\n",
    "    break\n",
    "  else:\n",
    "    update_parameters(percentage_update=30-(loop*2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "r3fIhAvhzGiB",
    "outputId": "89fdce5c-48c7-42a9-a55f-5398c385120e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>#crossval_repetitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>67</td>\n",
       "      <td>0.968661</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>37</td>\n",
       "      <td>0.957977</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>52</td>\n",
       "      <td>0.955861</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>0.954551</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>84</td>\n",
       "      <td>0.954231</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>84</td>\n",
       "      <td>0.947692</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>0.947161</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>37</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>67</td>\n",
       "      <td>0.944943</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>0.943462</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>0.94</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>0.936538</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>52</td>\n",
       "      <td>0.916484</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>0.911355</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  min_samples_split  min_samples_leaf max_features  n_estimators  \\\n",
       "0       7                  2                 1         None            67   \n",
       "1       6                  2                 1         None            37   \n",
       "2       3                  2                 1         None            52   \n",
       "3      10                  2                 1         None            50   \n",
       "4      11                  2                 1         None            84   \n",
       "5      13                  2                 2         None            84   \n",
       "6       2                  2                 1         None            28   \n",
       "7       8                  2                 2         None            37   \n",
       "8       9                  2                 2         None            67   \n",
       "9       0                  2                 2         None            40   \n",
       "10     12                  2                 2         None            50   \n",
       "11      1                  4                 2         None            40   \n",
       "12      5                  2                 3         None            52   \n",
       "13      4                  2                 3         None            28   \n",
       "\n",
       "   mean_accuracy #crossval_repetitions  \n",
       "0       0.968661                     9  \n",
       "1       0.957977                     9  \n",
       "2       0.955861                     7  \n",
       "3       0.954551                    10  \n",
       "4       0.954231                    10  \n",
       "5       0.947692                    10  \n",
       "6       0.947161                     7  \n",
       "7       0.946652                     9  \n",
       "8       0.944943                     9  \n",
       "9       0.943462                     5  \n",
       "10          0.94                    10  \n",
       "11      0.936538                     5  \n",
       "12      0.916484                     7  \n",
       "13      0.911355                     7  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_performers_df = params_df.sort_values(by='mean_accuracy', ascending=False).reset_index().copy()\n",
    "best_performers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL2qSBRcYerK"
   },
   "source": [
    "testing GridSearch best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soyLd0b760fN",
    "outputId": "2cf0e2f4-8ee9-41fb-d1c5-6f56ac28b447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 0.923], [1.0, 0.923], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 0.923], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]\n",
      "average of training accuracy:  1.0\n",
      "average of validation accuracy:  0.9754\n",
      "std of multiple hold-out validation accuracy:  0.0473\n"
     ]
    }
   ],
   "source": [
    "#repeating experiment n times to get an idea of variance and avr performance\n",
    "r = {}\n",
    "for _ in range(100):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.1, stratify=y)\n",
    "  clf = BaggingClassifier(DecisionTreeClassifier(min_samples_leaf=1, min_samples_split=2, max_features=0.8), n_estimators=200)\n",
    "  clf = clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_test)\n",
    "  y_pred_tr = clf.predict(X_train)\n",
    "  r[_] = [accuracy_score(y_train, y_pred_tr), round(accuracy_score(y_test, y_pred),3)]\n",
    "\n",
    "print([r.get(key) for key in [np.random.randint(0,100) for _ in range(10)]])\n",
    "print(\"average of training accuracy: \", round(np.array([_[0] for _ in r.values()]).mean(), 4))\n",
    "print(\"average of validation accuracy: \", round(np.array([_[1] for _ in r.values()]).mean(), 4))\n",
    "print(\"std of multiple hold-out validation accuracy: \", round(np.array([_[1] for _ in r.values()]).std(), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
