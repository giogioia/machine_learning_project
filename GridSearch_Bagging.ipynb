{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yDdr0jUpePNp"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11424/1719617585.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scikitplot.metrics import plot_roc\n",
    "from scikitplot.metrics import plot_precision_recall\n",
    "from scikitplot.metrics import plot_cumulative_gain\n",
    "from scikitplot.metrics import plot_lift_curve\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQXuF9oDXo7B"
   },
   "source": [
    "### MONK1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpUdxuv5pPOz"
   },
   "source": [
    "import and clean train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FlODP3pe0EwX"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11424/2187901779.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#import&clean Monk_train 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmonk1_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'monks-1_train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmonk1_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrename_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#import&clean Monk_train 1\n",
    "monk1_train = pd.read_csv('monks-1_train.csv', sep=' ', header= None)\n",
    "monk1_train.drop([0,8], axis=1, inplace = True)\n",
    "rename_dict = {}\n",
    "for i in range(2,8): \n",
    "  rename_dict[i] = f\"attr_{i-1}\"\n",
    "rename_dict.update({1:'target'})\n",
    "monk1_train.rename( columns=rename_dict, inplace =True)\n",
    "monk1_train = monk1_train[list(monk1_train)[1:] + list(monk1_train)[:-6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BBOwv210ssB"
   },
   "outputs": [],
   "source": [
    "#import&clean Monk_test 1\n",
    "monk1_test = pd.read_csv('monks-1_test.csv', sep=' ', header= None)\n",
    "monk1_test.drop([0,8], axis=1, inplace = True)\n",
    "rename_dict = {}\n",
    "for i in range(2,8): \n",
    "  rename_dict[i] = f\"attr_{i-1}\"\n",
    "rename_dict.update({1:'target'})\n",
    "monk1_test.rename( columns=rename_dict, inplace =True)\n",
    "monk1_test = monk1_test[list(monk1_test)[1:] + list(monk1_test)[:-6]]\n",
    "\n",
    "#remove training set from test set\n",
    "monk_temp = monk1_test.append(monk1_train, ignore_index =True)\n",
    "duplicated_indexes = monk_temp.duplicated(keep=False)\n",
    "monk1_test = monk_temp.drop(monk_temp.loc[duplicated_indexes,:].index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TrKv9Fk7EmPB"
   },
   "outputs": [],
   "source": [
    "X = monk1_train.iloc[:,:-1]\n",
    "y = monk1_train['target']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hNI7lC4_6bDM"
   },
   "outputs": [],
   "source": [
    "#with Pandas get_dummies\n",
    "X_encoded = pd.get_dummies(monk1_train.iloc[:,:-1].astype('str'), prefix_sep='=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "home made gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'min_samples_split': [2,4,6],\n",
    "              'min_samples_leaf': [1,2,3,4,5],\n",
    "              'max_features': [None,0.9,0.8,0.7],\n",
    "              'n_estimators': [200, 400, 600]}\n",
    "advanced_search = {'n_estimators':[30, 'int']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'min_samples_split': [2,4],\n",
    "              'min_samples_leaf': [1,2],\n",
    "              'max_features': [None,0.9],\n",
    "              'n_estimators': [50, 200]}\n",
    "advanced_search = {'n_estimators':[30, 'int']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(func, args):\n",
    "    return func(*args)\n",
    "\n",
    "def create_combination_df():\n",
    "  global params_df, previous_best\n",
    "  params_df = pd.DataFrame(data = list(wrapper(itertools.product, [list(params.values())[_] for _ in range(len(params.keys()))])), columns=list(params.keys()))\n",
    "  params_df = params_df.where(pd.notnull(params_df), None)\n",
    "  params_df['mean_accuracy'] = None\n",
    "  print(\"# of initial combinations: \", len(params_df.loc[params_df.mean_accuracy.isna()]))\n",
    "  previous_best = 0\n",
    "\n",
    "def update_combination_df():\n",
    "  global params_df\n",
    "  params_df = pd.concat([params_df, pd.DataFrame(data = list(wrapper(itertools.product, [list(params.values())[_] for _ in range(len(params.keys()))])), columns=list(params.keys()))], axis=0, ignore_index=True)\n",
    "  params_df = params_df.where(pd.notnull(params_df), None)\n",
    "  print(\"# of new combinations: \", len(params_df.loc[params_df.mean_accuracy.isna()]))\n",
    "\n",
    "def previous_accuracy_higher_than_new(new_best_result):\n",
    "  global previous_best\n",
    "  if previous_best >= new_best_result:\n",
    "      print('Stopping search because no improvements','\\nprevious_best = ',previous_best, '\\nnew_best = ',new_best_result)\n",
    "      previous_best = new_best_result \n",
    "      return True\n",
    "  else:\n",
    "      if previous_best != 0: print(f'Continuing search: new_best ({new_best_result}) vs previous_best ({previous_best} = {round(((new_best_result-previous_best)/previous_best)*100,3)}')\n",
    "      previous_best = new_best_result\n",
    "      return False \n",
    "\n",
    "def update_parameters(percentage_update):\n",
    "    global params\n",
    "    up, low = 1+1*(percentage_update/100), 1-1*(percentage_update/100)\n",
    "    key_list = list(advanced_search.keys())\n",
    "    for key in list(params.keys()):\n",
    "        if key in key_list:\n",
    "            best_param_value = params_df.sort_values(by='mean_accuracy', ascending=False).reset_index().loc[0,key]\n",
    "            if advanced_search[key][1] == 'int':\n",
    "                try: advanced_search[key][2] == 'min=2'\n",
    "                except IndexError: min_value = 1\n",
    "                else: min_value = 2\n",
    "                finally: \n",
    "                        params[key] = [int(round(max(best_param_value-max(best_param_value*(percentage_update/100),1), min_value))) , int(round(max(best_param_value+max(best_param_value*(percentage_update/100),1), min_value)))]                        \n",
    "                        #params[key] = [int(max(best_param_value*low, min_value)), int(max(best_param_value*up, min_value))]\n",
    "            elif advanced_search[key][1] == 'float':\n",
    "                params[key] = [best_param_value*low, best_param_value*up]\n",
    "        else:\n",
    "            best_param_value = params_df.sort_values(by='mean_accuracy', ascending=False).reset_index().loc[0,key]\n",
    "            params[key] = [best_param_value]\n",
    "    update_combination_df()\n",
    "\n",
    "def get_average_performance(num_rep, min_samples_split, min_samples_leaf, max_features, n_estimators):\n",
    "  mean_l = []\n",
    "  for _ in range(num_rep):\n",
    "    clf = BaggingClassifier(DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split= min_samples_split, min_samples_leaf= min_samples_leaf, max_features=max_features), \n",
    "                            n_estimators=n_estimators)\n",
    "    mean_scores = cross_val_score(clf, X_encoded, y, cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=True), error_score='raise')\n",
    "    #print('Accuracy: %0.4f (+/- %0.2f)' % (mean_scores.mean(), mean_scores.std() * 2))\n",
    "    mean_l.append(mean_scores.mean())\n",
    "  return (np.array(mean_l).mean())\n",
    "\n",
    "def launch_search(crossval_repetitions=3):\n",
    "  global params_df, temp_index\n",
    "  print('# of crossval_repetitions: ', crossval_repetitions)\n",
    "  temp_index = params_df.loc[params_df.mean_accuracy.isna()].index\n",
    "  for i in temp_index:\n",
    "    try:\n",
    "      #params_df.loc[i,'mean_accuracy'] = get_average_performance(10, params_df.loc[i,'min_samples_split'], params_df.loc[i,'min_samples_leaf'], params_df.loc[i,'max_features'])\n",
    "      params_df.loc[i,'mean_accuracy'] = wrapper(get_average_performance, list([crossval_repetitions]+ [params_df.loc[i,_] for _ in list(params.keys())])) \n",
    "      params_df.loc[i,'#crossval_repetitions'] = int(crossval_repetitions)\n",
    "      print(dict(params_df.loc[i,[_ for _ in list(params_df) if _ != '#crossval_repetitions']]))\n",
    "    except ValueError as E:\n",
    "      print(f'skipped combination {i}:', E)\n",
    "      pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of initial combinations:  2\n",
      "loop 0\n",
      "# of crossval_repetitions:  5\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 80, 'mean_accuracy': 0.9485897435897435}\n",
      "{'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 80, 'mean_accuracy': 0.9405128205128206}\n",
      "# of new combinations:  4\n",
      "loop 1\n",
      "# of crossval_repetitions:  7\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 56, 'mean_accuracy': 0.9605311355311354}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 104, 'mean_accuracy': 0.9519230769230769}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None, 'n_estimators': 56, 'mean_accuracy': 0.913003663003663}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None, 'n_estimators': 104, 'mean_accuracy': 0.9144688644688644}\n",
      "Continuing search: new_best (0.9605311355311354) vs previous_best (0.9485897435897435 = 1.259\n",
      "# of new combinations:  4\n",
      "loop 2\n",
      "# of crossval_repetitions:  9\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 40, 'mean_accuracy': 0.9552706552706552}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 72, 'mean_accuracy': 0.9632478632478632}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 40, 'mean_accuracy': 0.9267094017094016}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 72, 'mean_accuracy': 0.9487179487179487}\n",
      "Continuing search: new_best (0.9632478632478632) vs previous_best (0.9605311355311354 = 0.283\n",
      "# of new combinations:  4\n",
      "loop 3\n",
      "# of crossval_repetitions:  10\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 53, 'mean_accuracy': 0.9610897435897435}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'n_estimators': 91, 'mean_accuracy': 0.9533974358974359}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 53, 'mean_accuracy': 0.9396153846153845}\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'n_estimators': 91, 'mean_accuracy': 0.9497435897435895}\n",
      "Stopping search because no improvements \n",
      "previous_best =  0.9632478632478632 \n",
      "new_best =  0.9610897435897435\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_split': [2,4],\n",
    "              'min_samples_leaf': [2],\n",
    "              'max_features': [None],\n",
    "              'n_estimators': [80]}\n",
    "advanced_search = {'n_estimators':[30, 'int'], 'min_samples_leaf':[20,'int']}\n",
    "\n",
    "create_combination_df()\n",
    "for loop in range(10):\n",
    "  print(f'loop {loop}')\n",
    "  launch_search(crossval_repetitions=min(5+(loop*2),10))\n",
    "  if previous_accuracy_higher_than_new(params_df.loc[temp_index,'mean_accuracy'].max()): \n",
    "    break\n",
    "  else:\n",
    "    update_parameters(percentage_update=30-(loop*2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "r3fIhAvhzGiB",
    "outputId": "89fdce5c-48c7-42a9-a55f-5398c385120e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.975641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.96859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>0.967949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.967949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>0.960256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>0.959615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.953846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.952564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>0.951923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.951282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>0.951282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.942308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>0.937179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>0.926282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>0.919231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  min_samples_split  min_samples_leaf max_features  n_estimators  \\\n",
       "0      10                  4                 1          0.9            50   \n",
       "1       3                  2                 1          0.9           200   \n",
       "2       8                  4                 1         None            50   \n",
       "3      15                  4                 2          0.9           200   \n",
       "4      13                  4                 2         None           200   \n",
       "5       5                  2                 2         None           200   \n",
       "6      11                  4                 1          0.9           200   \n",
       "7       6                  2                 2          0.9            50   \n",
       "8       0                  2                 1         None            50   \n",
       "9       2                  2                 1          0.9            50   \n",
       "10      9                  4                 1         None           200   \n",
       "11      7                  2                 2          0.9           200   \n",
       "12     14                  4                 2          0.9            50   \n",
       "13      1                  2                 1         None           200   \n",
       "14     12                  4                 2         None            50   \n",
       "15      4                  2                 2         None            50   \n",
       "\n",
       "   mean_accuracy  \n",
       "0       0.975641  \n",
       "1        0.96859  \n",
       "2       0.967949  \n",
       "3       0.967949  \n",
       "4       0.960256  \n",
       "5       0.959615  \n",
       "6       0.953846  \n",
       "7       0.952564  \n",
       "8       0.951923  \n",
       "9       0.951282  \n",
       "10      0.951282  \n",
       "11          0.95  \n",
       "12      0.942308  \n",
       "13      0.937179  \n",
       "14      0.926282  \n",
       "15      0.919231  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_performers_df = params_df.sort_values(by='mean_accuracy', ascending=False).reset_index().copy()\n",
    "best_performers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL2qSBRcYerK"
   },
   "source": [
    "testing GridSearch best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soyLd0b760fN",
    "outputId": "2cf0e2f4-8ee9-41fb-d1c5-6f56ac28b447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 0.923], [1.0, 0.923], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 0.923], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]\n",
      "average of training accuracy:  1.0\n",
      "average of validation accuracy:  0.9754\n",
      "std of multiple hold-out validation accuracy:  0.0473\n"
     ]
    }
   ],
   "source": [
    "#repeating experiment n times to get an idea of variance and avr performance\n",
    "r = {}\n",
    "for _ in range(100):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.1, stratify=y)\n",
    "  clf = BaggingClassifier(DecisionTreeClassifier(min_samples_leaf=1, min_samples_split=2, max_features=0.8), n_estimators=200)\n",
    "  clf = clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_test)\n",
    "  y_pred_tr = clf.predict(X_train)\n",
    "  r[_] = [accuracy_score(y_train, y_pred_tr), round(accuracy_score(y_test, y_pred),3)]\n",
    "\n",
    "print([r.get(key) for key in [np.random.randint(0,100) for _ in range(10)]])\n",
    "print(\"average of training accuracy: \", round(np.array([_[0] for _ in r.values()]).mean(), 4))\n",
    "print(\"average of validation accuracy: \", round(np.array([_[1] for _ in r.values()]).mean(), 4))\n",
    "print(\"std of multiple hold-out validation accuracy: \", round(np.array([_[1] for _ in r.values()]).std(), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
